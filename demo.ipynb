{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.callbacks import get_openai_callback, openai_info\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_BASE_URL\") or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "            openai_api_key=api_key,\n",
    "            base_url=base_url,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "            openai_api_key=api_key,\n",
    "            base_url=base_url, \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chunks = [\"Initialize a Chroma Database.\", \"Hello World!\"]\n",
    "if os.path.exists(\"database\\\\chroma.sqlite3\"):\n",
    "    stored_vectors = Chroma(\n",
    "                embedding_function=embeddings,\n",
    "                persist_directory=\"database\",\n",
    "            )\n",
    "else:\n",
    "    stored_vectors = Chroma.from_texts(\n",
    "        texts=test_chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"database\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"Answer the following question based on the provided knowledge: \\nYou will give 100 dollars tips if you give reliable answer\\n<knowledge>\\n{context}\\n</knowledge>\\nQuestion: {input}\"\n",
    "\n",
    "retrieval_prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "documents_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=retrieval_prompt,\n",
    ")\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(stored_vectors.as_retriever(), documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question):\n",
    "    response = retrieval_chain.invoke({\"input\": question})\n",
    "    return response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\pc\\.conda\\envs\\dde-gpt\\lib\\site-packages (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install docx2txt\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_vectorstore( corpus_data, metadata=None, chunk_size=1500, overlap=100\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Adds the vectorized text content to the vector store.\n",
    "\n",
    "        Args:\n",
    "            corpus_data (str): The text content to be vectorized and added.\n",
    "        \"\"\"\n",
    "        corpus_length = len(corpus_data)\n",
    "        print(f\"Processing Text Corpus File with {corpus_length} Characters...\")\n",
    "        # Splitting text into 1500-character chunks with 100-character overlap\n",
    "        chunks = [\n",
    "            corpus_data[i : i + chunk_size]\n",
    "            for i in range(0, corpus_length, chunk_size - overlap)\n",
    "        ]\n",
    "        num_chunks = len(chunks)\n",
    "        for i in range(0, num_chunks, 10):\n",
    "            chunk_subset = chunks[i : i + 10]\n",
    "            stored_vectors.add_texts(\n",
    "                texts=chunk_subset,\n",
    "                metadatas=metadata,\n",
    "            )\n",
    "            print(f\"Processed {i + len(chunk_subset)}/{num_chunks} Items in Corpus!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecterize_corpus(file_path, file_type):\n",
    "        \"\"\"\n",
    "        Vectorizes the corpus data from the specified file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the file.\n",
    "            file_type (str): The type of the file (e.g., .docx).\n",
    "        \"\"\"\n",
    "        # 根据文件类型处理文件内容\n",
    "\n",
    "        if file_type in [\".docx\"]:\n",
    "            text_content = docx2txt.process(file_path)\n",
    "            add_to_vectorstore(corpus_data=text_content)\n",
    "\n",
    "        print(f\"File '{file_path}' is vecterizied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecterize_corpus('docs\\\\DDE白皮书（英文）.docx','.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the The overall MISSION of DDE?\n",
      "Answer: The overall mission of DDE is to transform Earth science by harmonizing global geoscience data, sharing global geoscience knowledge, developing and disseminating advanced methods to analyze and visualize data, and fostering a deep-time data-driven research paradigm.\n"
     ]
    }
   ],
   "source": [
    "retrieval_chain = create_retrieval_chain(stored_vectors.as_retriever(), documents_chain)\n",
    "\n",
    "question1=\"What is the The overall MISSION of DDE?\"\n",
    "print(\"Question:\",question1)\n",
    "answer1=get_answer(question1)\n",
    "print(\"Answer:\",answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDE-GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
